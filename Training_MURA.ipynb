{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuraTrainingDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,text_file,root_dir, transform = transforms.Compose([transforms.Resize((150,150)),\n",
    "                                                                          transforms.ToTensor(),\n",
    "                                                                          transforms.Normalize(\n",
    "                                                                              mean = [0.24808845, 0.24808845, 0.24808845],\n",
    "                                                                              std = [0.01409452, 0.01409452, 0.01409452])])):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "        #File with the Path\n",
    "        self.name_frame = pd.read_csv(text_file,sep=\",\",usecols=range(1),dtype = 'str',nrows = 10000)\n",
    "        #File with labels\n",
    "        self.label_frame = pd.read_csv(text_file,sep=\",\", usecols=[1], nrows=10000)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "                                       \n",
    "    def __len__(self):\n",
    "        return len(self.name_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Pull image\n",
    "        img_name = os.path.join(self.root_dir, self.name_frame.iloc[idx, 0])\n",
    "        \n",
    "        image = Image.open(img_name)\n",
    "        image = image.convert('RGB')\n",
    "        #Apply tensor transformations to images\n",
    "        image = self.transform(image) \n",
    "        # I included labels in the train_image_path file in excel using a find(\"positive\")\n",
    "        labels = self.label_frame.iloc[idx,0] \n",
    "        #Formatting for labels\n",
    "        labels = np.array(labels)\n",
    "        labels = np.reshape(labels, (1,1))\n",
    "        labels= torch.from_numpy(labels.astype('int'))\n",
    "\n",
    "        sample = {'image': image, 'labels': labels}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MuraTrainSet = MuraTrainingDataset(text_file ='/Users/JosephVele/MURA-v1.1/train_image_paths.csv',\n",
    "                                   root_dir = '/Users/JosephVele')\n",
    "\n",
    "MuraTrainLoader = torch.utils.data.DataLoader(MuraTrainSet,batch_size=100,shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean &std\n",
    "x=[]\n",
    "for i_batch,sample_batched in enumerate(MuraTrainLoader,0):\n",
    "    numpy_image = sample_batched['image'].numpy()\n",
    "    x.append(np.mean(numpy_image, axis=(0,2,3)))\n",
    "\n",
    "image_mean=np.mean(x, axis= (0))\n",
    "image_std=np.std(x, axis=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.214048e-06 -4.214048e-06 -4.214048e-06]\n",
      "[0.94273394 0.94273394 0.94273394]\n"
     ]
    }
   ],
   "source": [
    "#Confirm images have been normalized appropriately with 0 mean and 1 std\n",
    "print(image_mean)\n",
    "print(image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper-parameters\n",
    "#******************************#\n",
    "drp1 = .1 #Dropout Rate for Convolutional Layer\n",
    "drp2 = .5 #Dropout Rate for Dense Layer\n",
    "learning = .01 # Learning Rate \n",
    "moment =.9 #Momentum \n",
    "\n",
    "#******************************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=2, drop1 = .1, drop2 = .5):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 3.1 Initialization\n",
    "        #******************************#\n",
    "        # 1 input image channel, 10 output channels, 1x1 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=1) #Output = 75 x 75 x 10 \n",
    "        self.conv1_bn = nn.BatchNorm2d(10)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=2) #Output =18x18x20\n",
    "        self.conv2_bn = nn.BatchNorm2d(20)\n",
    "        self.conv2_drop = nn.Dropout2d(p=drop1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(20, 30, kernel_size=3)  #Output =8 x 8 x 30\n",
    "        self.conv3_bn = nn.BatchNorm2d(30)\n",
    "        self.conv3_drop = nn.Dropout2d(p=drop1)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(30, 40, kernel_size=3) #Output = 3 x 3 x 40 \n",
    "        self.conv4_bn = nn.BatchNorm2d(40)\n",
    "        self.conv4_drop = nn.Dropout2d(p=drop1)\n",
    "        \n",
    "        self.dense1 = nn.Linear(360, 50)\n",
    "        self.dense1_drop = nn.Dropout2d(p=drop2) \n",
    "        self.dense2 = nn.Linear(50, 25)\n",
    "        self.dense2_drop = nn.Dropout2d(p=drop2)\n",
    "        self.dense3 = nn.Linear(25, 1)\n",
    "                \n",
    "        \n",
    "        #******************************#\n",
    "    def forward(self, x):\n",
    "        # 3.2 Define Neural Network\n",
    "        #******************************#\n",
    "        \n",
    "        #convolutional layers\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2_bn(self.conv2(x))), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3_bn(self.conv3(x))), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv4_drop(self.conv4_bn(self.conv4(x))), 2))\n",
    "        \n",
    "        #flatten\n",
    "        x = x.view(-1, 360)\n",
    "        \n",
    "        #dense layers\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dense1_drop(x)\n",
    "        \n",
    "        x = F.relu(self.dense2(x))\n",
    "        x = self.dense2_drop(x)\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        #******************************#\n",
    "        return x\n",
    "        \n",
    "                       \n",
    "model = ConvNet(num_classes=2, drop1 = .1, drop2 = .5).to(device)\n",
    "# Note: what is the difference between 'same' and 'valid' padding? \n",
    "# Take a look at the outputs to understand the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Define criterion and optimizer\n",
    "#************************************#\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() #Binary Cross Entropy\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning, momentum=moment)\n",
    "\n",
    "#************************************#\n",
    "\n",
    "# 4.2 Train the model\n",
    "# 4.3 Please store and print training and validation loss&accuracy after each epoch\n",
    "#********************************************#\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "test_losses = []\n",
    "\n",
    "acc_data_train=[]\n",
    "acc_data_test=[]\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for i, sample_batched in enumerate(MuraTrainLoader,1):\n",
    "        inputs = sample_batched['image']\n",
    "        labels = sample_batched['labels']\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.view(len(sample_batched['labels']),-1)\n",
    "        loss = criterion(outputs.float(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss+= loss.item()\n",
    "        pred = (torch.sigmoid(outputs).data > 0.5).int()\n",
    "\n",
    "        labels = labels.int()\n",
    "\n",
    "        correct += (pred == labels).int().sum()\n",
    "\n",
    "\n",
    "    \n",
    "    #Print Results from first Epoch\n",
    "    #Accuracy\n",
    "    acc =  100.00 * float(correct) / float(len(MuraTrainLoader.dataset))\n",
    "    acc_data_train.append(acc)\n",
    "    #Average Loss\n",
    "    train_loss=float(train_loss)/float(i)\n",
    "    train_losses.append(train_loss)\n",
    "    # print statistics        \n",
    "    print('\\nTrain Epoch:{} Accuracy: {:.4f} \\t Average Loss: {:.4f}\\n'.format(epoch,\n",
    "            acc, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate 10\n"
     ]
    }
   ],
   "source": [
    "#Tuning Learning Rate\n",
    "for i in [10,1,.1,.01]:\n",
    "    for epoch in range(1,2):  # loop over the dataset multiple times\n",
    "        model = ConvNet(num_classes=2, drop1 = .1, drop2 = .5).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss() #Binary Cross Entropy\n",
    "        optimizer = optim.SGD(model.parameters(), lr=i, momentum=moment)\n",
    "        print('Learning Rate {}'.format(i) )\n",
    "        train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
