{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "%matplotlib inline\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuraDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,text_file,root_dir, transform ): #Normalize to pretrained VGGNet\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "        #File with the Path\n",
    "        self.name_frame = pd.read_csv(text_file,sep=\",\",usecols=[0],dtype = 'str',nrows = 1000)\n",
    "        #File with labels\n",
    "        self.label_frame = pd.read_csv(text_file,sep=\",\", usecols=[1], nrows = 1000)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "                                       \n",
    "    def __len__(self):\n",
    "        return len(self.name_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Pull image\n",
    "        img_name = os.path.join(self.root_dir, self.name_frame.iloc[idx, 0])\n",
    "        \n",
    "        #Apply adapative threshold to highlight key features in the image   \n",
    "        image = cv2.imread(img_name,0)\n",
    "        image = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)  \n",
    "        image = Image.fromarray(image)\n",
    "        image = image.convert('L')\n",
    "        \n",
    "        #Apply tensor transformations to images\n",
    "        image = self.transform(image) \n",
    "        \n",
    "        # I included labels in the train_image_path file in excel using a find(\"positive\")\n",
    "        labels = self.label_frame.iloc[idx,0] \n",
    "        \n",
    "        #Formatting for labels\n",
    "        labels = np.array(labels)\n",
    "        labels = np.reshape(labels, (1,1))\n",
    "        labels= torch.from_numpy(labels.astype('int'))\n",
    "\n",
    "        sample = {'image': image, 'labels': labels}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MuraTrainSet = MuraDataset(text_file ='/Users/JosephVele/MURA-v1.1/Shoulder_Mura.csv',\n",
    "                           root_dir = '/Users/JosephVele',\n",
    "                          transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                                          transforms.ToTensor(),\n",
    "                                                          transforms.Normalize(\n",
    "                                                              mean=[0.456],\n",
    "                                                              std= [0.225])]))\n",
    "\n",
    "MuraTrainLoader = torch.utils.data.DataLoader(MuraTrainSet,batch_size=100,shuffle=True, num_workers=0)\n",
    "\n",
    "MuraTestSet = MuraDataset(text_file ='/Users/JosephVele/MURA-v1.1/Shoulder_Mura_test.csv',\n",
    "                                   root_dir = '/Users/JosephVele')\n",
    "\n",
    "MuraTestLoader = torch.utils.data.DataLoader(MuraTestSet,batch_size=30,shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean &std - batch was sent to 8379 to match number of records in one batch\n",
    "\n",
    "for i_batch,sample_batched in enumerate(MuraTrainLoader,0):\n",
    "    numpy_image = sample_batched['image'].numpy()\n",
    "    image_mean = np.mean(numpy_image, axis=(0,2,3))\n",
    "    image_std = np.std(numpy_image, axis=(0,2,3))\n",
    "\n",
    "\n",
    "#image_mean=np.mean(x, axis= (0))\n",
    "#image_std=np.std(x, axis=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02527229]\n",
      "[0.96729124]\n"
     ]
    }
   ],
   "source": [
    "#Confirm images have been normalized appropriately with 0 mean and 1 std\n",
    "#This will help with vanishing gradient problem\n",
    "print(image_mean)\n",
    "print(image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /Users/JosephVele/.torch/models/densenet169-b2777c0a.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dense_net169 = models.densenet169(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1664])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for param in dense_net169.features.parameters():\n",
    "    param.requires_grad = False\n",
    "#Adjust to grayscale = 1 channel. Requires gradient is True by default\n",
    "dense_net169.features._modules['conv0']  = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "dense_net169.classifier = nn.Linear(in_features=1664, out_features=1, bias=True)\n",
    "#dense_net169\n",
    "\n",
    "for param in dense_net169.classifier.parameters():\n",
    "    print(param.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper-parameters\n",
    "#******************************#\n",
    "\n",
    "learning = 1e-3 # Learning Rate \n",
    "\n",
    "w = 1e-2\n",
    "b = [.9,999]\n",
    "#******************************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Define criterion and optimizer\n",
    "#************************************#\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "optimizer = optim.Adam(dense_net169.classifier.parameters(), lr=learning, weight_decay = w)\n",
    "\n",
    "#************************************#\n",
    "\n",
    "# 4.2 Train the model\n",
    "# 4.3 Please store and print training and validation loss&accuracy after each epoch\n",
    "#********************************************#\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "acc_data_train=[]\n",
    "acc_data_test=[]\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    dense_net169.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for i, sample_batched in enumerate(MuraTrainLoader,1):\n",
    "        inputs = sample_batched['image']\n",
    "        labels = sample_batched['labels']\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = dense_net169(inputs)\n",
    "        labels = labels.view(len(sample_batched['labels']),-1)\n",
    "        loss = criterion(outputs.float(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+= loss.item()\n",
    "        \n",
    "        pred = (torch.sigmoid(outputs).data > 0.5).int()\n",
    "        labels = labels.int()\n",
    "        correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "\n",
    "\n",
    "    \n",
    "    #Print Results from first Epoch\n",
    "    #Accuracy\n",
    "    acc =  100.00 * float(correct) / float(len(MuraTrainLoader.dataset))\n",
    "    acc_data_train.append(acc)\n",
    "    #Average Loss\n",
    "    train_loss=float(train_loss)/float(i)\n",
    "    train_losses.append(train_loss)\n",
    "    # print statistics        \n",
    "    print('Train Epoch:{} Loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(epoch,\n",
    "            train_loss, correct, len(MuraTrainLoader.dataset), acc))\n",
    "\n",
    "def test(epoch):\n",
    "    #Have our model in evaluation mode\n",
    "    dense_net169.eval()\n",
    "    #Set losses and Correct labels to zero\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, sample_batched in enumerate(MuraTestLoader,1):\n",
    "            inputs = sample_batched['image']\n",
    "            labels = sample_batched['labels']\n",
    "            outputs = dense_net169(inputs)\n",
    "            labels = labels.view(len(sample_batched['labels']),-1)\n",
    "            loss = criterion(outputs.float(), labels.float())\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            pred = (torch.sigmoid(outputs).data > 0.5).int()\n",
    "            labels = labels.int()\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "\n",
    "        test_loss = test_loss/i\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        acc =  100.00 * float(correct) / float(len(MuraTestLoader.dataset))\n",
    "        acc_data_test.append(acc)\n",
    "        print('Test Epoch:{} Loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(epoch,\n",
    "            test_loss, correct, len(MuraTestLoader.dataset),\n",
    "            acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1 Loss: 0.6220, Accuracy: 662/1000 (66.20%)\n",
      "\n",
      "Test Epoch:1 Loss: 0.6629, Accuracy: 347/562 (61.74%)\n",
      "\n",
      "Train Epoch:2 Loss: 0.6089, Accuracy: 697/1000 (69.70%)\n",
      "\n",
      "Test Epoch:2 Loss: 0.6609, Accuracy: 344/562 (61.21%)\n",
      "\n",
      "Train Epoch:3 Loss: 0.6054, Accuracy: 696/1000 (69.60%)\n",
      "\n",
      "Test Epoch:3 Loss: 0.6671, Accuracy: 340/562 (60.50%)\n",
      "\n",
      "Train Epoch:4 Loss: 0.5878, Accuracy: 704/1000 (70.40%)\n",
      "\n",
      "Test Epoch:4 Loss: 0.6670, Accuracy: 332/562 (59.07%)\n",
      "\n",
      "Train Epoch:5 Loss: 0.5859, Accuracy: 710/1000 (71.00%)\n",
      "\n",
      "Test Epoch:5 Loss: 0.6675, Accuracy: 333/562 (59.25%)\n",
      "\n",
      "Train Epoch:6 Loss: 0.5757, Accuracy: 729/1000 (72.90%)\n",
      "\n",
      "Test Epoch:6 Loss: 0.6538, Accuracy: 354/562 (62.99%)\n",
      "\n",
      "Train Epoch:7 Loss: 0.5683, Accuracy: 744/1000 (74.40%)\n",
      "\n",
      "Test Epoch:7 Loss: 0.6575, Accuracy: 351/562 (62.46%)\n",
      "\n",
      "Train Epoch:8 Loss: 0.5651, Accuracy: 736/1000 (73.60%)\n",
      "\n",
      "Test Epoch:8 Loss: 0.6579, Accuracy: 353/562 (62.81%)\n",
      "\n",
      "Train Epoch:9 Loss: 0.5553, Accuracy: 740/1000 (74.00%)\n",
      "\n",
      "Test Epoch:9 Loss: 0.6541, Accuracy: 360/562 (64.06%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train + Test per epoch\n",
    "for epoch in range(1,10): \n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alex Net on Body Part Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuraDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,text_file,root_dir, transform ): #Normalize to pretrained VGGNet\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "        #File with the Path\n",
    "        self.name_frame = pd.read_csv(text_file,sep=\",\",usecols=[0],dtype = 'str')\n",
    "        #File with labels\n",
    "        self.label_frame = pd.read_csv(text_file,sep=\",\")\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "                                       \n",
    "    def __len__(self):\n",
    "        return len(self.name_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Pull image\n",
    "        img_name = os.path.join(self.root_dir, self.name_frame.iloc[idx, 0])\n",
    "        \n",
    "        #Apply adapative threshold to highlight key features in the image   \n",
    "        image = cv2.imread(img_name,0)\n",
    "        image = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)  \n",
    "        image = Image.fromarray(image)\n",
    "        image = image.convert('L')\n",
    "        \n",
    "        #Apply tensor transformations to images\n",
    "        image = self.transform(image) \n",
    "        \n",
    "        # I included labels in the train_image_path file in excel using a find(\"positive\")\n",
    "        labels = self.label_frame.iloc[idx,10]\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        #Formatting for labels\n",
    "        labels = np.array(labels)\n",
    "        labels= torch.from_numpy(labels.astype('int64'))\n",
    "\n",
    "        sample = {'image': image, 'labels': labels}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "MuraTrainSet = MuraDataset(text_file ='/Users/JosephVele/MURA-v1.1/train_image_paths.csv',\n",
    "                           root_dir = '/Users/JosephVele',\n",
    "                          transform = transforms.Compose([transforms.Resize((227,227)),\n",
    "                                                          transforms.ToTensor(),\n",
    "                                                          transforms.Normalize(\n",
    "                                                              mean=[0.456],\n",
    "                                                              std= [0.225])]))\n",
    "\n",
    "MuraTrainLoader = torch.utils.data.DataLoader(MuraTrainSet,batch_size=100,shuffle=True, num_workers=0)\n",
    "\n",
    "MuraTestSet = MuraDataset(text_file ='/Users/JosephVele/MURA-v1.1/valid_image_paths.csv',\n",
    "                           root_dir = '/Users/JosephVele',\n",
    "                          transform = transforms.Compose([transforms.Resize((227,227)),\n",
    "                                                          transforms.ToTensor(),\n",
    "                                                          transforms.Normalize(\n",
    "                                                              mean=[0.456],\n",
    "                                                              std= [0.225])]))\n",
    "\n",
    "MuraTestLoader = torch.utils.data.DataLoader(MuraTestSet,batch_size=100,shuffle=True, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_net = models.alexnet(pretrained=True)\n",
    "for param in alex_net.parameters():\n",
    "    param.requires_grad = False\n",
    "#Adjust Model can read gray scale images\n",
    "alex_net.features._modules['0'] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "#Adjust Output\n",
    "alex_net.classifier._modules['6'] = nn.Linear(4096, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(alex_net.parameters(), lr=.01)\n",
    "\n",
    "#************************************#\n",
    "\n",
    "# 4.2 Train the model\n",
    "# 4.3 Please store and print training and validation loss&accuracy after each epoch\n",
    "#********************************************#\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "acc_data_train=[]\n",
    "acc_data_test=[]\n",
    "\n",
    "def alex_train(epoch, max_batch):\n",
    "    alex_net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for i, sample_batched in enumerate(MuraTrainLoader,1):\n",
    "        if i <max_batch:\n",
    "            inputs = sample_batched['image']\n",
    "            labels = sample_batched['labels']\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = alex_net(inputs)\n",
    "            loss = criterion(F.log_softmax(outputs, dim=1), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss+= loss.item()\n",
    "            pred = outputs.data.max(1, keepdim=True)[1].int()\n",
    "            #print(pred)\n",
    "            labels = labels.int()\n",
    "            #print(labels)\n",
    "\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "             \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    accuracy = float(100*float(correct)/(len(inputs)*max_batch))\n",
    "\n",
    "    acc_data_train.append([accuracy])\n",
    "    train_loss=float(train_loss)/float(i)\n",
    "    train_losses.append(train_loss)\n",
    "    # print statistics        \n",
    "    print('Train Epoch:{}  Accuracy: ({}/{}) {:.2f}%   Average Loss: {:.2f} \\n'.\n",
    "          format(epoch, correct,(len(inputs)*max_batch), accuracy, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: SGD\tLearning Rate: 0.1\tMomentum: 0.3\n",
      "Train Epoch:7  Accuracy: (393/2000) 19.65%   Average Loss: 28.09 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.1\tMomentum: 0.4\n",
      "Train Epoch:7  Accuracy: (391/2000) 19.55%   Average Loss: 10790.84 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.1\tMomentum: 0.5\n",
      "Train Epoch:7  Accuracy: (364/2000) 18.20%   Average Loss: 17635.25 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.1\tMomentum: 0.6\n",
      "Train Epoch:7  Accuracy: (373/2000) 18.65%   Average Loss: 11194.87 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.1\tMomentum: 0.7\n",
      "Train Epoch:7  Accuracy: (366/2000) 18.30%   Average Loss: 6271.56 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.1\tMomentum: 0.8\n",
      "Train Epoch:7  Accuracy: (391/2000) 19.55%   Average Loss: 69021.08 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.1\tMomentum: 0.9\n",
      "Train Epoch:7  Accuracy: (327/2000) 16.35%   Average Loss: 1736027.30 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.01\tMomentum: 0.3\n",
      "Train Epoch:7  Accuracy: (675/2000) 33.75%   Average Loss: 1.59 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.01\tMomentum: 0.4\n",
      "Train Epoch:7  Accuracy: (706/2000) 35.30%   Average Loss: 1.61 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.01\tMomentum: 0.5\n",
      "Train Epoch:7  Accuracy: (695/2000) 34.75%   Average Loss: 1.61 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.01\tMomentum: 0.6\n",
      "Train Epoch:7  Accuracy: (673/2000) 33.65%   Average Loss: 1.63 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.01\tMomentum: 0.7\n",
      "Train Epoch:7  Accuracy: (760/2000) 38.00%   Average Loss: 1.50 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.01\tMomentum: 0.8\n",
      "Train Epoch:7  Accuracy: (781/2000) 39.05%   Average Loss: 1.58 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.01\tMomentum: 0.9\n",
      "Train Epoch:7  Accuracy: (589/2000) 29.45%   Average Loss: 1.72 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.001\tMomentum: 0.3\n",
      "Train Epoch:7  Accuracy: (586/2000) 29.30%   Average Loss: 1.69 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.001\tMomentum: 0.4\n",
      "Train Epoch:7  Accuracy: (573/2000) 28.65%   Average Loss: 1.71 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.001\tMomentum: 0.5\n",
      "Train Epoch:7  Accuracy: (541/2000) 27.05%   Average Loss: 1.71 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.001\tMomentum: 0.6\n",
      "Train Epoch:7  Accuracy: (721/2000) 36.05%   Average Loss: 1.60 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.001\tMomentum: 0.7\n",
      "Train Epoch:7  Accuracy: (600/2000) 30.00%   Average Loss: 1.69 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.001\tMomentum: 0.8\n",
      "Train Epoch:7  Accuracy: (734/2000) 36.70%   Average Loss: 1.58 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 0.001\tMomentum: 0.9\n",
      "Train Epoch:7  Accuracy: (602/2000) 30.10%   Average Loss: 1.67 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 1e-05\tMomentum: 0.3\n",
      "Train Epoch:7  Accuracy: (225/2000) 11.25%   Average Loss: 1.94 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 1e-05\tMomentum: 0.4\n",
      "Train Epoch:7  Accuracy: (371/2000) 18.55%   Average Loss: 1.83 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 1e-05\tMomentum: 0.5\n",
      "Train Epoch:7  Accuracy: (262/2000) 13.10%   Average Loss: 1.93 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 1e-05\tMomentum: 0.6\n",
      "Train Epoch:7  Accuracy: (220/2000) 11.00%   Average Loss: 1.96 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 1e-05\tMomentum: 0.7\n",
      "Train Epoch:7  Accuracy: (296/2000) 14.80%   Average Loss: 1.84 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 1e-05\tMomentum: 0.8\n",
      "Train Epoch:7  Accuracy: (443/2000) 22.15%   Average Loss: 1.80 \n",
      "\n",
      "Optimizer: SGD\tLearning Rate: 1e-05\tMomentum: 0.9\n",
      "Train Epoch:7  Accuracy: (353/2000) 17.65%   Average Loss: 1.84 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 0.1\t WeightDecay: 0.1\n",
      "Train Epoch:7  Accuracy: (336/2000) 16.80%   Average Loss: 46.24 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 0.1\t WeightDecay: 0.01\n",
      "Train Epoch:7  Accuracy: (363/2000) 18.15%   Average Loss: 35.40 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 0.1\t WeightDecay: 0.001\n",
      "Train Epoch:7  Accuracy: (420/2000) 21.00%   Average Loss: 79.12 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 0.01\t WeightDecay: 0.1\n",
      "Train Epoch:7  Accuracy: (533/2000) 26.65%   Average Loss: 1.77 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 0.01\t WeightDecay: 0.01\n",
      "Train Epoch:7  Accuracy: (576/2000) 28.80%   Average Loss: 1.79 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 0.01\t WeightDecay: 0.001\n",
      "Train Epoch:7  Accuracy: (587/2000) 29.35%   Average Loss: 1.79 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 0.001\t WeightDecay: 0.1\n",
      "Train Epoch:7  Accuracy: (647/2000) 32.35%   Average Loss: 1.65 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 0.001\t WeightDecay: 0.01\n",
      "Train Epoch:7  Accuracy: (869/2000) 43.45%   Average Loss: 1.43 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 0.001\t WeightDecay: 0.001\n",
      "Train Epoch:7  Accuracy: (715/2000) 35.75%   Average Loss: 1.60 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 1e-05\t WeightDecay: 0.1\n",
      "Train Epoch:7  Accuracy: (441/2000) 22.05%   Average Loss: 1.80 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 1e-05\t WeightDecay: 0.01\n",
      "Train Epoch:7  Accuracy: (271/2000) 13.55%   Average Loss: 1.93 \n",
      "\n",
      "Optimizer: Adam\t Learning Rate: 1e-05\t WeightDecay: 0.001\n",
      "Train Epoch:7  Accuracy: (262/2000) 13.10%   Average Loss: 1.87 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning - Grid Search \n",
    "learning_rates = [.1,.01,.001, .00001]\n",
    "momentums = [.3,.4,.5,.6, .7, .8, .9]\n",
    "w = [.1,.01,.001]\n",
    "\n",
    "for i in [1,2]: #Test different optimizer\n",
    "    for j in range(len(learning_rates)):    \n",
    "        if i ==1:\n",
    "            for k in range(len(momentums)):\n",
    "                #Reset Model per test\n",
    "                alex_net = models.alexnet(pretrained=True)\n",
    "                for param in alex_net.parameters():\n",
    "                    param.requires_grad = False\n",
    "                alex_net.features._modules['0'] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "                #Adjust Output\n",
    "                alex_net.classifier._modules['6'] = nn.Linear(4096, 7)\n",
    "                \n",
    "                optimizer = optim.SGD(alex_net.parameters(), \n",
    "                                  lr=learning_rates[j], momentum=momentums[k])\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                \n",
    "                print('Optimizer: SGD\\tLearning Rate: {}\\tMomentum: {}'.\n",
    "                      format (learning_rates[j], momentums[k]))\n",
    "                alex_train(1,20)\n",
    "                \n",
    "        else: \n",
    "            for k in range(len(w)):\n",
    "                #Reset Model per test\n",
    "                alex_net = models.alexnet(pretrained=True)\n",
    "                for param in alex_net.parameters():\n",
    "                    param.requires_grad = False\n",
    "                    \n",
    "                alex_net.features._modules['0'] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "                #Adjust Output\n",
    "                alex_net.classifier._modules['6'] = nn.Linear(4096, 7)\n",
    "                \n",
    "                optimizer = optim.Adam(alex_net.parameters(), \n",
    "                                       lr=learning_rates[j], weight_decay = w[k], amsgrad=True)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "                print('Optimizer: Adam\\t Learning Rate: {}\\t WeightDecay: {}'.\n",
    "                      format (learning_rates[j], w[k]))\n",
    "                alex_train(1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_net = models.alexnet(pretrained=True)\n",
    "for param in alex_net.parameters():\n",
    "    param.requires_grad = False\n",
    "alex_net.features._modules['0'] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "#Adjust Output\n",
    "alex_net.classifier._modules['6'] = nn.Linear(4096, 7)\n",
    "\n",
    "optimizer = optim.Adam(alex_net.parameters(), \n",
    "                                       lr=.001, weight_decay = .01, amsgrad=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "acc_data_train=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1  Accuracy: (5914/10000) 59.14%   Average Loss: 1.17 \n",
      "\n",
      "Train Epoch:2  Accuracy: (7571/10000) 75.71%   Average Loss: 0.70 \n",
      "\n",
      "Train Epoch:3  Accuracy: (7943/10000) 79.43%   Average Loss: 0.59 \n",
      "\n",
      "Train Epoch:4  Accuracy: (8225/10000) 82.25%   Average Loss: 0.51 \n",
      "\n",
      "Train Epoch:5  Accuracy: (8373/10000) 83.73%   Average Loss: 0.46 \n",
      "\n",
      "Train Epoch:6  Accuracy: (8583/10000) 85.83%   Average Loss: 0.41 \n",
      "\n",
      "Train Epoch:7  Accuracy: (8713/10000) 87.13%   Average Loss: 0.36 \n",
      "\n",
      "Train Epoch:8  Accuracy: (8814/10000) 88.14%   Average Loss: 0.34 \n",
      "\n",
      "Train Epoch:9  Accuracy: (8875/10000) 88.75%   Average Loss: 0.32 \n",
      "\n",
      "Train Epoch:10  Accuracy: (8902/10000) 89.02%   Average Loss: 0.31 \n",
      "\n",
      "Train Epoch:11  Accuracy: (8993/10000) 89.93%   Average Loss: 0.28 \n",
      "\n",
      "Train Epoch:12  Accuracy: (9054/10000) 90.54%   Average Loss: 0.27 \n",
      "\n",
      "Train Epoch:13  Accuracy: (9113/10000) 91.13%   Average Loss: 0.25 \n",
      "\n",
      "Train Epoch:14  Accuracy: (9109/10000) 91.09%   Average Loss: 0.25 \n",
      "\n",
      "Train Epoch:15  Accuracy: (9136/10000) 91.36%   Average Loss: 0.25 \n",
      "\n",
      "Train Epoch:16  Accuracy: (9164/10000) 91.64%   Average Loss: 0.23 \n",
      "\n",
      "Train Epoch:17  Accuracy: (9147/10000) 91.47%   Average Loss: 0.25 \n",
      "\n",
      "Train Epoch:18  Accuracy: (9236/10000) 92.36%   Average Loss: 0.22 \n",
      "\n",
      "Train Epoch:19  Accuracy: (9218/10000) 92.18%   Average Loss: 0.22 \n",
      "\n",
      "Train Epoch:20  Accuracy: (9253/10000) 92.53%   Average Loss: 0.21 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,21):\n",
    "    alex_train(epoch,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Model Parameters:  57017031\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#************************************#\n",
    "total_params = sum(p.numel() for p in alex_net.parameters())\n",
    "print('Number of Model Parameters: ', total_params)\n",
    "#************************************#\n",
    "\n",
    "body_losses = train_losses\n",
    "body_accuracy = acc_data_train\n",
    "\n",
    "# 5.2 Summarize history for loss and make loss vs.epoch plot\n",
    "#************************************#\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(body_losses)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Cross Entropy Loss')\n",
    "ax1.set_title('CNN Loss vs Epoch')\n",
    "ax2.plot(body_accuracy)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "plt.subplots_adjust(right=1.25)\n",
    "ax2.set_title('CNN Accuracy vs Epoch')\n",
    "\n",
    "fig.text(0.64, 1,'Body Classifcation Performance',ha='center', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "acc_data_test=[]\n",
    "\n",
    "def alex_test(epoch):\n",
    "    #Have our model in evaluation mode\n",
    "    alex_net.eval()\n",
    "    #Set losses and Correct labels to zero\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, sample_batched in enumerate(MuraTestLoader,1):\n",
    "\n",
    "            inputs = sample_batched['image']\n",
    "            labels = sample_batched['labels']\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = alex_net(inputs)\n",
    "            loss = criterion(F.log_softmax(outputs, dim=1), labels)\n",
    "            test_loss+= loss.item()\n",
    "            pred = outputs.data.max(1, keepdim=True)[1].int()\n",
    "            #print(pred)\n",
    "            labels = labels.int()\n",
    "            #print(labels)\n",
    "\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "             \n",
    "    \n",
    "        accuracy = float(100*float(correct)/(len(MuraTestLoader.dataset)))\n",
    "\n",
    "        acc_data_test.append([accuracy])\n",
    "        test_loss=float(test_loss)/float(i)\n",
    "        test_losses.append(test_loss)\n",
    "        # print statistics        \n",
    "        print('Test Epoch:{}  Accuracy: ({}/{}) {:.2f}%   Average Loss: {:.2f} \\n'.\n",
    "              format(epoch, correct,len(MuraTestLoader.dataset), accuracy, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:1  Accuracy: (2909/3196) 91.02%   Average Loss: 0.29 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alex_test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
